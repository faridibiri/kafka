# ğŸ“¦ SystÃ¨me de Gestion de Commandes avec Kafka Streams

Un projet Spring Boot 3.1 complet illustrant l'utilisation avancÃ©e de **Apache Kafka** avec des **Producers**, **Consumers** et **Kafka Streams** pour le traitement en temps rÃ©el.

## ğŸ¯ Objectifs d'Apprentissage

Ce projet dÃ©montre les concepts Kafka suivants:

### 1. **Producers (Producteurs)**
- âœ… Envoi asynchrone de messages avec callbacks
- âœ… Headers personnalisÃ©s pour mÃ©tadonnÃ©es
- âœ… Partitionnement par clÃ© (orderId)
- âœ… Idempotence et retry automatique
- âœ… Compression des messages (Snappy)
- âœ… Batching pour performance optimale

### 2. **Consumers (Consommateurs)**
- âœ… Multiples consumer groups
- âœ… Traitement parallÃ¨le avec concurrence
- âœ… Batch processing pour les Ã©vÃ©nements
- âœ… Extraction des headers Kafka
- âœ… Gestion des offsets
- âœ… Error handling avec ErrorHandlingDeserializer

### 3. **Kafka Streams**
- âœ… AgrÃ©gations en temps rÃ©el
- âœ… FenÃªtres temporelles (Time Windows)
- âœ… Comptage et statistiques
- âœ… Filtrage et transformation
- âœ… DÃ©tection de patterns
- âœ… Analyses avancÃ©es

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   REST API  â”‚ â”€â”€â–º order.created
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚             â”‚              â”‚
        â–¼             â–¼             â–¼              â–¼
  OrderConsumer  Validation   Inventory      EventLog
                 Consumer     Consumer       Consumer
                      â”‚             â”‚
                      â–¼             â–¼
              order.validated  order.inventory
                      â”‚             â”‚
                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
                     Payment Consumer
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                 â–¼
              order.shipped    order.notifications
                    â”‚                 â”‚
                    â–¼                 â–¼
              Shipping         Notification
              Consumer          Consumer

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Kafka Streams Analytics        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Comptage par statut (5 min)       â”‚
â”‚ â€¢ DÃ©tection commandes haute valeur  â”‚
â”‚ â€¢ Calcul revenu total (10 min)      â”‚
â”‚ â€¢ Commandes par client              â”‚
â”‚ â€¢ Produits populaires (15 min)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Topics Kafka

| Topic | Partitions | Description |
|-------|-----------|-------------|
| `order.created` | 5 | Nouvelles commandes crÃ©Ã©es |
| `order.validated` | 5 | Commandes validÃ©es |
| `order.payment` | 3 | Paiements en cours |
| `order.shipped` | 3 | Commandes expÃ©diÃ©es |
| `order.events` | 5 | Tous les Ã©vÃ©nements de changement d'Ã©tat |
| `order.notifications` | 3 | Notifications clients |
| `order.analytics` | 3 | RÃ©sultats d'analyse en temps rÃ©el |
| `order.inventory` | 5 | Gestion du stock |
| `order.dead-letter` | 1 | Messages en erreur |
| `order.retry` | 3 | Retry automatique |

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis
- Java 17+
- Maven 3.8+
- Docker & Docker Compose

### 1. DÃ©marrer Kafka

```bash
docker-compose up -d
```

Cela dÃ©marre:
- ğŸ˜ **Zookeeper** (port 2181)
- ğŸ¯ **Kafka** (port 9092)
- ğŸ–¥ï¸ **Kafka UI** (http://localhost:8090)

### 2. Compiler le projet

```bash
mvn clean install
```

### 3. DÃ©marrer l'application

```bash
mvn spring-boot:run
```

L'application dÃ©marre sur **http://localhost:8080**

## ğŸ§ª Tester le SystÃ¨me

### 1. CrÃ©er une commande normale

```bash
curl -X POST http://localhost:8080/api/orders/example | \
curl -X POST http://localhost:8080/api/orders \
  -H "Content-Type: application/json" \
  -d @-
```

### 2. CrÃ©er une commande haute valeur (>1000â‚¬)

```bash
curl -X POST http://localhost:8080/api/orders/example/high-value | \
curl -X POST http://localhost:8080/api/orders \
  -H "Content-Type: application/json" \
  -d @-
```

### 3. CrÃ©er une commande personnalisÃ©e

```bash
curl -X POST http://localhost:8080/api/orders \
  -H "Content-Type: application/json" \
  -d '{
    "customerId": "CUST-001",
    "customerName": "Sophie Martin",
    "customerEmail": "sophie.martin@example.com",
    "phoneNumber": "+33 6 12 34 56 78",
    "priority": "EXPRESS",
    "items": [
      {
        "productId": "PROD-001",
        "productName": "iPhone 15 Pro",
        "sku": "IPH15P-256-BLK",
        "quantity": 2,
        "unitPrice": 1299.99,
        "totalPrice": 2599.98,
        "category": "Smartphones",
        "weight": 0.3
      }
    ],
    "shippingAddress": {
      "street": "10 Rue de Rivoli",
      "city": "Paris",
      "state": "Ãle-de-France",
      "postalCode": "75001",
      "country": "France",
      "phoneNumber": "+33 6 12 34 56 78"
    },
    "billingAddress": {
      "street": "10 Rue de Rivoli",
      "city": "Paris",
      "state": "Ãle-de-France",
      "postalCode": "75001",
      "country": "France",
      "phoneNumber": "+33 6 12 34 56 78"
    },
    "paymentInfo": {
      "paymentMethod": "CREDIT_CARD",
      "cardLastFour": "5678",
      "paymentProcessor": "Stripe"
    },
    "notes": "Livraison express demandÃ©e"
  }'
```

### 4. VÃ©rifier la santÃ©

```bash
curl http://localhost:8080/api/orders/health
```

## ğŸ“ˆ Visualisation avec Kafka UI

AccÃ©dez Ã  **http://localhost:8090** pour:

- ğŸ“‹ Voir tous les topics et leurs messages
- ğŸ“Š Monitorer les consumer groups et leur lag
- ğŸ” Rechercher et filtrer les messages
- ğŸ“ˆ Visualiser les mÃ©triques de performance
- âš™ï¸ GÃ©rer les configurations Kafka

## ğŸ” Concepts Kafka DÃ©taillÃ©s

### Producers - Patterns ImplÃ©mentÃ©s

#### 1. **Fire-and-Forget avec Callback**
```java
orderKafkaTemplate.send(record)
    .whenComplete((result, ex) -> {
        // Gestion asynchrone du rÃ©sultat
    });
```

#### 2. **Headers PersonnalisÃ©s**
```java
record.headers().add(new RecordHeader("priority", "EXPRESS".getBytes()));
record.headers().add(new RecordHeader("customer-id", customerId.getBytes()));
```

#### 3. **Idempotence**
```yaml
enable.idempotence: true
acks: all
retries: 3
```

### Consumers - Patterns ImplÃ©mentÃ©s

#### 1. **Single Record Processing**
```java
@KafkaListener(topics = "order.created")
public void consume(Order order) {
    // Traitement message par message
}
```

#### 2. **Batch Processing**
```java
@KafkaListener(topics = "order.events")
public void consumeBatch(List<OrderEvent> events) {
    // Traitement par lot pour performance
}
```

#### 3. **Header Extraction**
```java
@KafkaListener(topics = "order.created")
public void consume(
    @Payload Order order,
    @Header(KafkaHeaders.RECEIVED_PARTITION) int partition,
    @Header(KafkaHeaders.OFFSET) long offset
) {
    // AccÃ¨s aux mÃ©tadonnÃ©es Kafka
}
```

#### 4. **Multiple Consumer Groups**
- `order-processing-group` - Traitement principal
- `validation-group` - Validation des commandes
- `inventory-group` - Gestion du stock
- `payment-group` - Traitement des paiements
- `event-logging-group` - Log des Ã©vÃ©nements
- `notification-group` - Envoi de notifications

### Kafka Streams - Analyses ImplÃ©mentÃ©es

#### 1. **Comptage par Statut (FenÃªtre de 5 min)**
```java
orderEventsStream
    .groupBy((key, event) -> event.getStatus())
    .windowedBy(TimeWindows.ofSizeWithNoGrace(Duration.ofMinutes(5)))
    .count()
```

#### 2. **DÃ©tection Commandes Haute Valeur**
```java
orderStream
    .filter((key, order) -> order.getTotalAmount() > 1000)
    .peek((key, order) -> log.warn("HIGH VALUE ORDER"))
```

#### 3. **Calcul Revenu Total (FenÃªtre de 10 min)**
```java
orderStream
    .groupBy((key, order) -> "TOTAL_REVENUE")
    .windowedBy(TimeWindows.ofSizeWithNoGrace(Duration.ofMinutes(10)))
    .aggregate(() -> 0.0, (key, order, agg) -> agg + order.getTotal())
```

#### 4. **Produits Populaires (FenÃªtre de 15 min)**
```java
orderStream
    .flatMapValues(order -> order.getItems())
    .groupBy((key, item) -> item.getProductId())
    .windowedBy(TimeWindows.ofSizeWithNoGrace(Duration.ofMinutes(15)))
    .count()
```

## ğŸ”„ Flux de Traitement Complet

1. **CrÃ©ation** â†’ REST API reÃ§oit commande
2. **Publication** â†’ Producer envoie sur `order.created`
3. **Confirmation** â†’ OrderConsumer confirme rÃ©ception
4. **Validation** â†’ ValidationConsumer valide les donnÃ©es
   - âœ… Email valide
   - âœ… Adresse complÃ¨te
   - âœ… Montants corrects
   - âœ… QuantitÃ©s positives
5. **Inventaire** â†’ InventoryConsumer vÃ©rifie le stock
6. **Paiement** â†’ PaymentConsumer traite le paiement
7. **ExpÃ©dition** â†’ Si succÃ¨s, commande expÃ©diÃ©e
8. **Notification** â†’ NotificationConsumer envoie email
9. **Analytics** â†’ Kafka Streams analyse en temps rÃ©el

## ğŸ“Š Monitoring et MÃ©triques

### Actuator Endpoints

- **Health**: http://localhost:8080/actuator/health
- **Metrics**: http://localhost:8080/actuator/metrics
- **Prometheus**: http://localhost:8080/actuator/prometheus

### Logs Ã  Observer

```bash
# DÃ©marrer avec logs dÃ©taillÃ©s
mvn spring-boot:run

# Observer les logs en temps rÃ©el
tail -f logs/application.log
```

Logs importants:
- ğŸ“¤ Messages envoyÃ©s (partition, offset)
- ğŸ”µ Messages reÃ§us (consumer group, partition)
- âœ… SuccÃ¨s de traitement
- âŒ Erreurs et retry
- ğŸ“Š Analyses Streams
- ğŸš¨ Alertes haute valeur

## âš™ï¸ Configuration Importante

### Producer Configuration
```yaml
acks: all                          # Attendre confirmation de tous les replicas
retries: 3                         # 3 tentatives en cas d'Ã©chec
enable.idempotence: true           # Ã‰viter les duplications
compression.type: snappy           # Compression des messages
linger.ms: 10                      # Batching pour performance
batch.size: 32768                  # Taille des batches
```

### Consumer Configuration
```yaml
auto-offset-reset: earliest        # Lire depuis le dÃ©but
enable-auto-commit: true           # Commit automatique des offsets
max-poll-records: 100              # Max messages par poll
fetch-min-bytes: 1024              # Attendre min 1KB
fetch-max-wait-ms: 500             # Attendre max 500ms
```

### Streams Configuration
```yaml
commit.interval.ms: 1000           # Commit toutes les secondes
num.stream.threads: 2              # 2 threads de traitement
cache.max.bytes.buffering: 0       # Pas de cache (temps rÃ©el)
```

## ğŸ› ï¸ FonctionnalitÃ©s AvancÃ©es

### 1. Dead Letter Queue (DLQ)
Messages en erreur sont envoyÃ©s vers `order.dead-letter` pour investigation.

### 2. Retry Topic
Messages temporairement en Ã©chec sont envoyÃ©s vers `order.retry`.

### 3. Priority Routing
Messages sont routÃ©s selon leur prioritÃ© (EXPRESS, URGENT, etc.).

### 4. Async Processing
Traitement asynchrone des notifications avec `@Async`.

### 5. Idempotence
Ã‰vite les duplications avec idempotence activÃ©e cÃ´tÃ© producer.

## ğŸ“š Ressources pour Apprendre

### Concepts ClÃ©s DÃ©montrÃ©s

1. **Producers**
   - Synchrone vs Asynchrone
   - Callbacks et gestion d'erreurs
   - Partitionnement et routing
   - Compression et batching

2. **Consumers**
   - Consumer groups et parallÃ©lisme
   - Offset management
   - Batch vs single record
   - Error handling

3. **Kafka Streams**
   - KStream et KTable
   - Windowing (tumbling, hopping)
   - Aggregations et counting
   - Filtering et mapping
   - Joins et enrichments

## ğŸ”§ DÃ©veloppement

### Structure du Projet

```
src/main/java/com/example/kafka/
â”œâ”€â”€ config/              # Configurations Kafka
â”œâ”€â”€ controller/          # REST API
â”œâ”€â”€ consumer/            # Tous les consumers
â”œâ”€â”€ producer/            # Tous les producers
â”œâ”€â”€ streams/             # Kafka Streams processors
â””â”€â”€ model/              # Domain models
```

### Ajouter un Nouveau Consumer

```java
@KafkaListener(
    topics = "mon-topic",
    groupId = "mon-group",
    containerFactory = "monContainerFactory"
)
public void consume(Order order) {
    // Votre logique ici
}
```

### Ajouter un Nouveau Stream

```java
@Autowired
public void buildMyStream(StreamsBuilder streamsBuilder) {
    KStream<String, String> stream = streamsBuilder
        .stream("input-topic");

    stream
        .filter(...)
        .mapValues(...)
        .to("output-topic");
}
```

## ğŸ§¹ ArrÃªt et Nettoyage

```bash
# ArrÃªter l'application
Ctrl+C

# ArrÃªter Kafka
docker-compose down

# Nettoyer les volumes (ATTENTION: supprime les donnÃ©es)
docker-compose down -v
```

## ğŸ› Troubleshooting

### Kafka ne dÃ©marre pas
```bash
docker-compose logs kafka
# VÃ©rifier les erreurs dans les logs
```

### Consumer ne reÃ§oit pas les messages
- VÃ©rifier le consumer group
- VÃ©rifier l'offset (earliest vs latest)
- VÃ©rifier les logs de dÃ©sÃ©rialisation

### Streams ne traite pas
- VÃ©rifier l'application-id
- VÃ©rifier les state stores
- VÃ©rifier les logs Kafka Streams

## ğŸ“ Exercices Pratiques

1. **Ajouter un nouveau consumer** pour gÃ©rer les retours
2. **CrÃ©er un stream** pour dÃ©tecter les clients fidÃ¨les (>5 commandes)
3. **ImplÃ©menter un DLQ** pour les messages en erreur
4. **Ajouter des mÃ©triques** personnalisÃ©es avec Micrometer
5. **CrÃ©er un consumer batch** pour optimiser les notifications

## ğŸ“ Conclusion

Ce projet couvre tous les aspects fondamentaux et avancÃ©s de Kafka:
- âœ… Producers avec diffÃ©rentes stratÃ©gies
- âœ… Consumers avec patterns variÃ©s
- âœ… Kafka Streams pour analytics temps rÃ©el
- âœ… Gestion d'erreurs et retry
- âœ… Monitoring et mÃ©triques
- âœ… Best practices de production

Parfait pour comprendre Kafka dans un contexte rÃ©el d'e-commerce! ğŸš€